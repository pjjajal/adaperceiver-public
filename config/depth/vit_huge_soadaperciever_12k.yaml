defaults:
  - override hydra/job_logging: none

seed: 1348

trainer:
  devices: 1
  num_nodes: 1
  # For available strategies look at the PyTorch Lightning docs.
  # strategy: auto
  strategy: ddp_find_unused_parameters_true
  # strategy: ddp
  # Look at the PyTorch Lightning docs for available precision.
  precision: bf16-mixed

  # logging settings
  wandb: true
  wandb_project: adaperceiver_depth
  wandb_save_dir: "."
  log_every_n_steps: 10
  gradnorm_logging: true
  rich_print: false

  # checkpointing settings
  checkpoint_save_dir: null
  checkpoint_name: null
  save_loc: null # no need to specify this.
  resume_checkpoint: null

  # grad checkpointing
  grad_checkpointing: false

model:
  compile: true
  compile_mode: "default" # [default, max-autotune, no-autotune]
  model_checkpoint: ""
  mat_dims: [832] # 832 is the final dimension.
  token_grans: [32, 64, 96, 128, 192, 256]
  mask_type: block # [block, causal, null]
  encoder_config:
    # adapter type: [patch_embed, conv]
    adapter_type: "patch_embed"
    conv_adapter_model: null
    # image settings
    img_size: 224
    in_channels: 3
    patch_size: 14
    use_fourier: false
    fourier_bands: 8
    # classification
    num_classes: 150
    # encoder settings
    num_heads: 13
    embed_dim: 832
    depth: 21
    max_latent_tokens: 256
    max_latent_tokens_mult: 2
    rope_theta: 10000
    ffn_ratio: 2.57
    qkv_bias: true
    proj_bias: true
    ls_init_values: 1.0e-5
    # layers
    act_layer: "gelu"
    norm_layer: "layernorm"
    ffn_layer: "mlp"
    attn_layer: "flex"
    # other
    process_token_init: "learned"
    use_embed_ffn: true
    use_output_ffn: true
    output_feat_dim: 1280
    # regularization
    proj_drop: 0.0
    attn_drop: 0.0
    drop_path: 0.0
    head_drop: 0.0
    depth_head_drop: 0.0
    cat_cls: false

dataset:
  num_proc: 16
  name: nyu_depth
  min_depth: 0.001
  max_depth: 10.0
  bins: 256
  transforms:
    img_size: [448, 602]
    rotation: 2.5
    # normalize
    mean: [0.48145466, 0.4578275, 0.40821073]
    std: [0.26862954, 0.26130258, 0.27577711]
    # colour jitter
    jitter:
      enable: true
      brightness: 0.25
      contrast: 0.25
      saturation: 0.25
      hue: 0.1


  # dataloader settings
  batch_size: 4
  num_workers: 8
  val_batch_size: 4
  val_num_workers: 8
  pin_memory: true

  # distributed sampler
  use_distributed_sampler: false # this is false because we are using hf datasets.

loss:
  sig_loss_weight: 2.0
  sig_loss_warmup: 500
  grad_loss_weight: 0.5
  # adaptive losses
  token_loss:
    enable: true
    weight: 1.0
    sample_tokens: false # if false, it will use all tokens.
    token_loss_weights: [1, 1, 1, 1, 1, 1] # this NEEDS to be the length of num_tokens.
    # token_loss_weights: [1] # this NEEDS to be the length of num_tokens.
  depth_loss:
    enable: false
    weight: 1
    depth_loss_type: "linear" # [linear, exp, constant]
  matyr_loss:
    enable: false
    matyr_loss_weights: [1.0]
    # matyr_loss_weights: [0.2, 0.4, 0.8, 1.0]

optimizer:
  # general settings
  total_steps: null # no need to specify this.
  max_epochs: 16
  optimizer: nadamw
  lr: 0.5e-4
  weight_decay: 0.1
  betas: [0.90, 0.999]
  caution: true
  grad_clip: 3.0
  ema: 0.9995
  accumulate_grad_batches: 1
  overfit_batches: 0.0 # for debugging purposes, [0.0, 1.0]
  # shampoo specific settings
  preconditioning_frequency: 30
  max_preconditioner_dim: 8192
  start_preconditioning_step: 500
  # scheduler settings
  schedule: cosine
  warmup_steps: 1500
  warmup_lr: 1.0e-7
  min_lr: 1.0e-7
  power: 1.0
  output_adapters: false
